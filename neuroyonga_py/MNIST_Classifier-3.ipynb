{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb598ef-5fca-43e7-8d52-1acff2c2607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:56:31.492647: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D,MaxPool2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098057de-70f8-4a14-bb6e-81a1544d67a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train.shape, y_train.shape , x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1646ddd-ad1e-4a5c-b4c3-450c7ea7434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_input_image(i):\n",
    "    plt.imshow(x_train[i], cmap ='binary')\n",
    "    plt.title(y_train[i])\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde2bc96-2b72-4728-9eeb-170b1dc6c507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plot_input_image(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c38e1ac-67f2-4f3d-88f0-e1537b3f6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the image\n",
    "\n",
    "#normalizing\n",
    "x_train = x_train.astype(np.float32)/255\n",
    "x_test = x_test.astype(np.float32)/255\n",
    "\n",
    "#reshaping the image for ease of calculation (expanding the dimensions to (28,28,1))\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "#converting y to as one_hot vector since it ranges from 0 to 9\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc67cce3-9668-4263-bfb1-e2a0dc9fb8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:56:42.738102: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#building the model\n",
    "model = Sequential()\n",
    "\n",
    " #first convolutional layer added 3,3 kernel size is an industry standard the activation function may be changed\n",
    "model.add(Conv2D(32, (3,3), input_shape = (28,28,1), activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    " #adding more convolutional layers but removing the input shape since it should only be provided in the input layer\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    " #this is for the classification part\n",
    "model.add(Dense(10, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9382639-87dd-4bd6-9d80-7829f9897398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c63e67-d594-4357-b131-33dd996af9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters, biases = model.layers[0].get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "931826bb-b463-476f-a212-583c96a59f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter 0 coefficients:\n",
      "[[ 0.02836028 -0.0264978  -0.0009886 ]\n",
      " [-0.09670553  0.0621095  -0.05746588]\n",
      " [-0.06709731 -0.01969922  0.06269751]]\n",
      "Filter 1 coefficients:\n",
      "[[ 0.1311978  -0.05766995 -0.02584008]\n",
      " [ 0.04826683  0.04040422  0.10744345]\n",
      " [ 0.1197051   0.10779485  0.08437583]]\n",
      "Filter 2 coefficients:\n",
      "[[ 1.4023732e-01 -1.0324575e-01  8.3571270e-02]\n",
      " [-3.8444407e-02  1.2348592e-04 -4.4108480e-02]\n",
      " [ 2.8295830e-02 -1.8810898e-02 -2.0726956e-02]]\n",
      "Filter 3 coefficients:\n",
      "[[ 0.0217021  -0.13002376  0.05092204]\n",
      " [ 0.05063426 -0.07464511  0.1378778 ]\n",
      " [ 0.06462632 -0.01962077 -0.03609172]]\n",
      "Filter 4 coefficients:\n",
      "[[-0.14114563  0.02389272  0.09849197]\n",
      " [-0.12789713  0.10317992  0.07572652]\n",
      " [-0.06467084  0.00405034  0.00752075]]\n",
      "Filter 5 coefficients:\n",
      "[[-0.01209673  0.13206626  0.01136175]\n",
      " [ 0.11849211  0.11160477  0.0542943 ]\n",
      " [ 0.08239707  0.04688826 -0.12263745]]\n",
      "Filter 6 coefficients:\n",
      "[[ 0.11218728  0.10536547 -0.09420021]\n",
      " [ 0.03926906  0.02348949  0.14125867]\n",
      " [ 0.08823353  0.00988039  0.0017982 ]]\n",
      "Filter 7 coefficients:\n",
      "[[-0.12275876 -0.10159734  0.0789389 ]\n",
      " [-0.01657294 -0.03637833 -0.01394328]\n",
      " [ 0.13030554  0.10399818  0.11755581]]\n",
      "Filter 8 coefficients:\n",
      "[[ 0.13039522  0.01334168 -0.05629972]\n",
      " [ 0.12986644  0.0486504   0.092116  ]\n",
      " [-0.12640196  0.10522921  0.03539099]]\n",
      "Filter 9 coefficients:\n",
      "[[ 0.10295124  0.05671424 -0.12911962]\n",
      " [-0.01317289  0.04374494  0.13226442]\n",
      " [-0.09773012 -0.02849285 -0.02743933]]\n",
      "Filter 10 coefficients:\n",
      "[[-0.1334269  -0.09142479  0.11388154]\n",
      " [ 0.09187025 -0.13527475 -0.09293512]\n",
      " [-0.10326497  0.11364295 -0.05966002]]\n",
      "Filter 11 coefficients:\n",
      "[[-0.03330065 -0.06823776  0.09037076]\n",
      " [ 0.00514786  0.01452479 -0.07335525]\n",
      " [-0.00770923 -0.12000982 -0.05142953]]\n",
      "Filter 12 coefficients:\n",
      "[[ 0.04674932  0.0805847   0.06762365]\n",
      " [ 0.0675946   0.08288586 -0.07844903]\n",
      " [ 0.13784917  0.12230839  0.1122763 ]]\n",
      "Filter 13 coefficients:\n",
      "[[-0.02778545  0.09520303  0.04233108]\n",
      " [ 0.04103316  0.12504913  0.07651281]\n",
      " [ 0.11911149 -0.00658706 -0.11997109]]\n",
      "Filter 14 coefficients:\n",
      "[[ 0.00376129  0.03860447  0.03739147]\n",
      " [ 0.12803479 -0.11851702 -0.04298244]\n",
      " [-0.1329419  -0.07573984 -0.13805991]]\n",
      "Filter 15 coefficients:\n",
      "[[ 0.10840385 -0.02331924 -0.11258944]\n",
      " [ 0.08026071  0.138422   -0.03460559]\n",
      " [-0.0812503  -0.01124433 -0.12400626]]\n",
      "Filter 16 coefficients:\n",
      "[[-0.07532506  0.07240689 -0.08795378]\n",
      " [-0.02864426  0.08380401 -0.12748297]\n",
      " [-0.09749798 -0.06845453  0.11442874]]\n",
      "Filter 17 coefficients:\n",
      "[[-0.06685454 -0.11724611 -0.05931986]\n",
      " [ 0.04474485  0.10596697  0.10566579]\n",
      " [ 0.00174408  0.11374547 -0.02186096]]\n",
      "Filter 18 coefficients:\n",
      "[[ 0.13324241 -0.04290595  0.06559579]\n",
      " [ 0.05360086  0.11631756  0.11645024]\n",
      " [-0.11748291 -0.065792    0.0640099 ]]\n",
      "Filter 19 coefficients:\n",
      "[[ 0.08149272  0.10775676  0.01327066]\n",
      " [ 0.13222359 -0.03611455  0.02932611]\n",
      " [-0.03564958 -0.00224081  0.04256643]]\n",
      "Filter 20 coefficients:\n",
      "[[-0.07443178  0.00047067 -0.06568716]\n",
      " [ 0.10721827  0.07673442  0.02725051]\n",
      " [-0.13093951  0.10105114  0.11029924]]\n",
      "Filter 21 coefficients:\n",
      "[[ 0.04454874  0.0225345  -0.07791524]\n",
      " [ 0.11474057  0.04337491  0.05801211]\n",
      " [-0.04038972 -0.05978507 -0.04335611]]\n",
      "Filter 22 coefficients:\n",
      "[[-0.0678554  -0.12530553 -0.11493516]\n",
      " [-0.02152632 -0.10459738  0.11230363]\n",
      " [-0.12481623 -0.03851381 -0.05467784]]\n",
      "Filter 23 coefficients:\n",
      "[[ 0.08777368  0.02657428 -0.02309734]\n",
      " [-0.08947675  0.0181872   0.0709195 ]\n",
      " [-0.03055011 -0.09994207 -0.04761928]]\n",
      "Filter 24 coefficients:\n",
      "[[-0.0268098  -0.03420243 -0.02490171]\n",
      " [ 0.08019823 -0.08411936  0.04911658]\n",
      " [ 0.12855981  0.11189841  0.06553297]]\n",
      "Filter 25 coefficients:\n",
      "[[-0.07548615 -0.08204627  0.01136883]\n",
      " [-0.01368544 -0.13635898  0.13745849]\n",
      " [-0.05792011  0.04634528  0.13366704]]\n",
      "Filter 26 coefficients:\n",
      "[[ 0.09555455  0.0683765   0.11008151]\n",
      " [-0.03467709  0.09361714 -0.01701714]\n",
      " [-0.0687422  -0.03036204  0.00795594]]\n",
      "Filter 27 coefficients:\n",
      "[[ 0.09816244 -0.08238487  0.02674176]\n",
      " [-0.07469445  0.08355382 -0.11621708]\n",
      " [ 0.09092726 -0.04572036 -0.05772695]]\n",
      "Filter 28 coefficients:\n",
      "[[-0.08826572 -0.03612225 -0.00661735]\n",
      " [ 0.13710935  0.07998466  0.08013698]\n",
      " [-0.0090383   0.02271858  0.06151994]]\n",
      "Filter 29 coefficients:\n",
      "[[-0.01514812 -0.09871576 -0.02917561]\n",
      " [-0.0146787   0.12069385  0.02044979]\n",
      " [ 0.14002548 -0.09509327  0.05301915]]\n",
      "Filter 30 coefficients:\n",
      "[[-0.06980796  0.02782191 -0.11034755]\n",
      " [ 0.04641235  0.03270687 -0.04216229]\n",
      " [ 0.14061774 -0.0338868  -0.1182939 ]]\n",
      "Filter 31 coefficients:\n",
      "[[ 0.12331419 -0.0101146   0.00396892]\n",
      " [-0.0801537   0.00262003  0.03295392]\n",
      " [-0.0244728  -0.0918896   0.13156228]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(32):\n",
    "    filter_i = filters[:, :, 0, i]\n",
    "    print(f\"Filter {i} coefficients:\\n{filter_i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dd4e916-7cd8-494e-83f5-f40ab2a1681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = keras.losses.categorical_crossentropy, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e372835a-58d4-49c3-a193-d87faa98f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "\n",
    "# Define callbacks\n",
    "es = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=4, verbose=1)\n",
    "mc = ModelCheckpoint(\"./best_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "# List of callbacks\n",
    "callbacks = [es, mc]\n",
    "\n",
    "# Check if the best_model.h5 file was created\n",
    "#if os.path.exists(\"./best_model.h5\"):\n",
    "#    print(\"The best_model.h5 file was successfully created.\")\n",
    "#else:\n",
    "#    print(\"Error: The best_model.h5 file was not created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af0df578-a376-4eb5-ba77-3170db7d7ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.2151 - accuracy: 0.9358\n",
      "Epoch 1: val_accuracy improved from -inf to 0.97367, saving model to ./best_model.h5\n",
      "1313/1313 [==============================] - 33s 25ms/step - loss: 0.2150 - accuracy: 0.9358 - val_loss: 0.0850 - val_accuracy: 0.9737\n",
      "Epoch 2/5\n",
      "1313/1313 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9759\n",
      "Epoch 2: val_accuracy improved from 0.97367 to 0.97911, saving model to ./best_model.h5\n",
      "1313/1313 [==============================] - 32s 24ms/step - loss: 0.0766 - accuracy: 0.9759 - val_loss: 0.0666 - val_accuracy: 0.9791\n",
      "Epoch 3/5\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9824\n",
      "Epoch 3: val_accuracy improved from 0.97911 to 0.98528, saving model to ./best_model.h5\n",
      "1313/1313 [==============================] - 37s 28ms/step - loss: 0.0566 - accuracy: 0.9824 - val_loss: 0.0520 - val_accuracy: 0.9853\n",
      "Epoch 4/5\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9853\n",
      "Epoch 4: val_accuracy did not improve from 0.98528\n",
      "1313/1313 [==============================] - 40s 30ms/step - loss: 0.0461 - accuracy: 0.9853 - val_loss: 0.0508 - val_accuracy: 0.9843\n",
      "Epoch 5/5\n",
      "1312/1313 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9878\n",
      "Epoch 5: val_accuracy improved from 0.98528 to 0.98750, saving model to ./best_model.h5\n",
      "1313/1313 [==============================] - 45s 34ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.0430 - val_accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_split=0.3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d37eebf-dd92-4263-bfd3-573ea0b96c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_S = keras.models.load_model(\"/Users/damdam/best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7613f97e-f14f-445e-975e-6aca1cea8e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0333 - accuracy: 0.9888\n",
      "the model accuracy is 0.9887999892234802\n"
     ]
    }
   ],
   "source": [
    "score = model_S.evaluate(x_test, y_test)\n",
    "print(f\"the model accuracy is {score[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec2e2b1e-82e4-4d08-a2bc-924c45989c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape: (10000, 28, 28, 1)\n",
      "Data type: float32\n",
      "Pixel value range: 0.0 to 1.0\n",
      "The pixel values are normalized between 0 and 1.\n",
      "The images are in grayscale.\n",
      "Label distribution: {0.0: 90000, 1.0: 10000}\n",
      "Pixel mean value: 0.13251467049121857\n",
      "Pixel standard deviation: 0.3104802668094635\n"
     ]
    }
   ],
   "source": [
    "# Assuming x_test is your test dataset and y_test are the corresponding labels\n",
    "\n",
    "# Print the shape of the dataset (number of images, height, width, channels)\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "\n",
    "# Print the data type of the dataset\n",
    "print(f\"Data type: {x_test.dtype}\")\n",
    "\n",
    "# Print the range of pixel values\n",
    "print(f\"Pixel value range: {x_test.min()} to {x_test.max()}\")\n",
    "\n",
    "# If the data is normalized, state that\n",
    "if x_test.max() == 1:\n",
    "    print(\"The pixel values are normalized between 0 and 1.\")\n",
    "\n",
    "# If the images are in grayscale, they will have only one channel\n",
    "if x_test.shape[-1] == 1:\n",
    "    print(\"The images are in grayscale.\")\n",
    "\n",
    "# Print the distribution of the labels\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(f\"Label distribution: {dict(zip(unique, counts))}\")\n",
    "\n",
    "# Additionally, if you want to see more details like mean and standard deviation\n",
    "print(f\"Pixel mean value: {x_test.mean()}\")\n",
    "print(f\"Pixel standard deviation: {x_test.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aa24fb5-7e84-4d03-bc2d-d78d3e77278b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "========================================================\n",
      "Layer Name: conv2d\n",
      "Layer Type: Conv2D\n",
      "Output Shape: (None, 26, 26, 32)\n",
      "Input Shape: (None, 28, 28, 1)\n",
      "Kernel Size: (3, 3)\n",
      "Strides: (1, 1)\n",
      "Number of Filters: 32\n",
      "Weights Shape: (3, 3, 1, 32)\n",
      "Biases Shape: (32,)\n",
      "========================================================\n",
      "\n",
      "\n",
      "========================================================\n",
      "Layer Name: max_pooling2d\n",
      "Layer Type: MaxPooling2D\n",
      "Output Shape: (None, 13, 13, 32)\n",
      "Input Shape: (None, 26, 26, 32)\n",
      "Strides: (2, 2)\n",
      "Pool Size: (2, 2)\n",
      "========================================================\n",
      "\n",
      "\n",
      "========================================================\n",
      "Layer Name: conv2d_1\n",
      "Layer Type: Conv2D\n",
      "Output Shape: (None, 11, 11, 64)\n",
      "Input Shape: (None, 13, 13, 32)\n",
      "Kernel Size: (3, 3)\n",
      "Strides: (1, 1)\n",
      "Number of Filters: 64\n",
      "Weights Shape: (3, 3, 32, 64)\n",
      "Biases Shape: (64,)\n",
      "========================================================\n",
      "\n",
      "\n",
      "========================================================\n",
      "Layer Name: max_pooling2d_1\n",
      "Layer Type: MaxPooling2D\n",
      "Output Shape: (None, 5, 5, 64)\n",
      "Input Shape: (None, 11, 11, 64)\n",
      "Strides: (2, 2)\n",
      "Pool Size: (2, 2)\n",
      "========================================================\n",
      "\n",
      "\n",
      "========================================================\n",
      "Layer Name: flatten\n",
      "Layer Type: Flatten\n",
      "Output Shape: (None, 1600)\n",
      "Input Shape: (None, 5, 5, 64)\n",
      "========================================================\n",
      "\n",
      "\n",
      "========================================================\n",
      "Layer Name: dropout\n",
      "Layer Type: Dropout\n",
      "Output Shape: (None, 1600)\n",
      "Input Shape: (None, 1600)\n",
      "Dropout Rate: 0.25\n",
      "========================================================\n",
      "\n",
      "\n",
      "========================================================\n",
      "Layer Name: dense\n",
      "Layer Type: Dense\n",
      "Output Shape: (None, 10)\n",
      "Input Shape: (None, 1600)\n",
      "Number of Neurons: 10\n",
      "Weights Shape: (1600, 10)\n",
      "Biases Shape: (10,)\n",
      "========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "\n",
    "# Assuming `model` is your Keras Sequential model\n",
    "\n",
    "# Print the model summary for a quick overview\n",
    "model.summary()\n",
    "\n",
    "# Iterate over each layer to print detailed information\n",
    "for layer in model.layers:\n",
    "    print(\"\\n========================================================\")\n",
    "    print(f\"Layer Name: {layer.name}\")\n",
    "    print(f\"Layer Type: {type(layer).__name__}\")\n",
    "    print(f\"Output Shape: {layer.output_shape}\")\n",
    "    if hasattr(layer, 'input_shape'):\n",
    "        print(f\"Input Shape: {layer.input_shape}\")\n",
    "    if hasattr(layer, 'kernel_size'):\n",
    "        print(f\"Kernel Size: {layer.kernel_size}\")\n",
    "    if hasattr(layer, 'strides'):\n",
    "        print(f\"Strides: {layer.strides}\")\n",
    "    if hasattr(layer, 'pool_size'):  # For pooling layers\n",
    "        print(f\"Pool Size: {layer.pool_size}\")\n",
    "    if hasattr(layer, 'rate'):  # For dropout layers\n",
    "        print(f\"Dropout Rate: {layer.rate}\")\n",
    "    if isinstance(layer, Dense):\n",
    "        print(f\"Number of Neurons: {layer.units}\")\n",
    "    if hasattr(layer, 'filters'):\n",
    "        print(f\"Number of Filters: {layer.filters}\")\n",
    "    \n",
    "    # Print weights and biases\n",
    "    if layer.get_weights():\n",
    "        weights = layer.get_weights()[0]  # Weights\n",
    "        biases = layer.get_weights()[1]  # Biases\n",
    "        print(f\"Weights Shape: {weights.shape}\")\n",
    "        print(f\"Biases Shape: {biases.shape}\")\n",
    "        # Uncomment the following lines if you want to print the actual values\n",
    "        #print(\"Weights:\", weights)\n",
    "        #print(\"Biases:\", biases)\n",
    "    print(\"========================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fc9a211-0e97-4ae8-b74d-eff5495cf990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 weights:\n",
      "[[[[-1.95070937e-01  1.71990663e-01  3.41304034e-01  6.08410016e-02\n",
      "    -3.62101197e-01 -1.21435568e-01  1.08001254e-01 -4.92951572e-01\n",
      "     1.60097033e-01  1.18975058e-01 -2.06471652e-01  1.54403105e-01\n",
      "     1.06243096e-01 -1.41423315e-01  2.02369153e-01  1.91001534e-01\n",
      "    -3.95409763e-01 -7.74291083e-02  7.75996223e-02  3.87755595e-03\n",
      "    -3.33385989e-02 -3.26927640e-02 -2.74402022e-01  1.82822526e-01\n",
      "    -1.82900280e-02 -3.06729168e-01  5.74964024e-02  2.40712777e-01\n",
      "    -1.92554474e-01 -1.94939077e-01  1.24538727e-01  1.16250776e-01]]\n",
      "\n",
      "  [[-1.51675493e-01 -5.36559746e-02  1.60708025e-01 -1.75658733e-01\n",
      "     9.87874195e-02  1.45655513e-01  8.61228257e-02 -3.27467233e-01\n",
      "     4.67665121e-02  1.75872043e-01 -1.62528530e-01  1.73936620e-01\n",
      "     6.71929643e-02  9.87177417e-02  2.72918880e-01  6.85869008e-02\n",
      "    -5.03449142e-01 -3.00584733e-01  3.38873751e-02  1.23152092e-01\n",
      "     2.54012702e-04  3.63709591e-02 -5.47194600e-01  2.50394970e-01\n",
      "    -2.31212750e-01 -2.03127012e-01  9.67983678e-02  9.21870098e-02\n",
      "    -1.44147396e-01 -3.22150946e-01  1.71634719e-01  8.87777805e-02]]\n",
      "\n",
      "  [[ 1.18726179e-01  1.99982692e-02  2.74375647e-01  7.05293491e-02\n",
      "     2.73454428e-01  1.16024941e-01 -1.74363866e-01 -2.39466112e-02\n",
      "    -1.08811766e-01 -1.97320983e-01  2.93110400e-01  3.43873620e-01\n",
      "     4.25943360e-02  1.17731482e-01  2.83625126e-01 -2.19046786e-01\n",
      "    -6.15909874e-01 -2.73588151e-01  9.65665132e-02  7.30177984e-02\n",
      "    -3.11770827e-01 -3.56322452e-02 -6.72640651e-03  1.96168080e-01\n",
      "    -3.92605990e-01  9.28272232e-02  1.29164994e-01 -7.21951295e-03\n",
      "    -7.22155273e-02 -1.44206837e-01 -2.73141384e-01 -1.17183756e-03]]]\n",
      "\n",
      "\n",
      " [[[-3.41526568e-01  1.55382892e-02  1.93825260e-01  4.98674549e-02\n",
      "    -4.64155167e-01  1.63435221e-01 -2.06460264e-02 -9.16350558e-02\n",
      "     1.17571972e-01 -1.31092012e-01  2.01230168e-01  1.15121879e-01\n",
      "     8.23003426e-02  2.46463325e-02  2.76489556e-01  1.94054827e-01\n",
      "    -4.54306334e-01  1.01044737e-01 -2.04146258e-03  2.46631652e-01\n",
      "     1.02496192e-01  2.23871842e-01 -4.78105217e-01 -1.72449961e-01\n",
      "     1.47551477e-01 -2.78625458e-01 -3.12123168e-02  1.41791835e-01\n",
      "     1.33531466e-01  2.85054278e-02  2.56256193e-01 -1.64840624e-01]]\n",
      "\n",
      "  [[ 9.47454050e-02  2.80894749e-02  1.06595360e-01  2.79447902e-03\n",
      "     1.35102734e-01  2.13387161e-01  6.69766217e-02  4.55217101e-02\n",
      "     1.08134560e-01  1.82434648e-01 -5.30389249e-01  1.84444010e-01\n",
      "     3.97935063e-02  2.47618377e-01  3.85942496e-02  1.99063122e-01\n",
      "    -1.66647449e-01  1.33180380e-01  2.03599170e-01 -4.08627503e-02\n",
      "     1.37537077e-01  1.35448694e-01 -9.75276753e-02  1.47041962e-01\n",
      "    -1.40795410e-01 -1.13284357e-01  1.65851757e-01  2.05495000e-01\n",
      "     1.02316871e-01  2.11191818e-01  9.07556340e-02  9.22792852e-02]]\n",
      "\n",
      "  [[ 1.41747236e-01  1.33768737e-01 -1.87175527e-01  2.54532009e-01\n",
      "     2.45345026e-01 -3.56390653e-03  1.71678111e-01  1.13878451e-01\n",
      "     1.19813286e-01  2.38815382e-01 -4.36930269e-01  9.13687944e-02\n",
      "    -1.18466623e-01  9.85171199e-02  1.09259300e-02 -2.72072971e-01\n",
      "     1.52315088e-02  1.74047872e-01  2.39493728e-01  4.35834937e-03\n",
      "    -3.57338190e-02  5.44851646e-02  3.69183838e-01  2.35701621e-01\n",
      "    -3.37029877e-03  3.16031843e-01  6.18949309e-02 -3.89059722e-01\n",
      "     1.50118187e-01  1.23084918e-01 -4.48292226e-01  9.11313146e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.63331524e-01  6.89415187e-02 -1.26847863e-01  9.27262753e-02\n",
      "    -2.23068371e-01  1.55540243e-01 -5.65506704e-03  3.34466279e-01\n",
      "    -1.70980379e-01 -2.78326273e-01  2.73006439e-01 -3.31527114e-01\n",
      "     1.36095256e-01  1.46732479e-01 -4.39662278e-01 -4.50517498e-02\n",
      "    -1.91047624e-01  6.82987943e-02 -3.66975188e-01 -1.54529527e-01\n",
      "    -1.87157661e-01 -2.87678298e-02 -4.74212974e-01 -4.26447690e-01\n",
      "     2.61007369e-01 -3.40304822e-02 -1.51003107e-01  2.73303658e-01\n",
      "     2.18031183e-02  2.79188097e-01  3.72609228e-01 -1.70853272e-01]]\n",
      "\n",
      "  [[ 1.16209112e-01  9.30478573e-02 -4.03252423e-01  2.71638762e-02\n",
      "     4.04876992e-02  5.70069142e-02  4.99841981e-02  3.09613615e-01\n",
      "     1.33560508e-01 -5.32737598e-02  3.43179673e-01 -5.32206476e-01\n",
      "     1.93187013e-01  8.77786055e-02 -4.37696934e-01  5.38876690e-02\n",
      "     2.50127792e-01  2.08668768e-01 -2.03846455e-01 -2.06624806e-01\n",
      "     1.84228286e-01 -9.24045816e-02  5.41861281e-02 -4.03782725e-01\n",
      "     3.05947363e-01  1.87684104e-01 -1.60781406e-02 -1.27978817e-01\n",
      "     3.59778069e-02  1.39907617e-02  3.40330042e-02 -1.34790197e-01]]\n",
      "\n",
      "  [[ 2.28634879e-01  1.73023380e-02 -3.81974131e-01 -1.35995045e-01\n",
      "     1.09053485e-01 -3.35398376e-01 -2.17852518e-02  1.99287757e-01\n",
      "     3.39703225e-02  1.15625501e-01 -1.18458513e-02 -3.06357890e-01\n",
      "     1.16573371e-01 -2.47655749e-01 -3.62321407e-01 -2.43649453e-01\n",
      "     5.31067967e-01  5.36299720e-02  1.67098850e-01 -1.13224201e-02\n",
      "     1.98618531e-01 -1.91063508e-01  2.15120792e-01 -9.52238441e-02\n",
      "     1.91480741e-01  3.00370783e-01  7.70012364e-02 -4.98888642e-01\n",
      "     1.48658929e-02  1.78821366e-02 -3.69784385e-01  2.14824155e-01]]]]\n",
      "\n",
      "Layer 1 weights:\n",
      "[-0.01137722 -0.15716328 -0.00513657 -0.10996636 -0.00242654 -0.16014244\n",
      " -0.12664469 -0.04115178 -0.14982457 -0.10517339  0.03310348  0.02990956\n",
      " -0.12767598 -0.20487787  0.07445565 -0.04054843  0.08578363 -0.01389972\n",
      " -0.12953398 -0.06510478 -0.07321225 -0.04320597  0.1637144  -0.00747526\n",
      " -0.01653858 -0.02462305 -0.14418136 -0.02426468 -0.03278752 -0.02028703\n",
      " -0.00583331 -0.0980236 ]\n",
      "\n",
      "Layer 2 weights:\n",
      "[[[[-1.40667751e-01 -1.03337010e-02  1.98831651e-02 ...  6.71879426e-02\n",
      "     1.99627012e-01 -1.45010322e-01]\n",
      "   [-8.18902925e-02  3.29834484e-02 -8.68638083e-02 ...  4.85234819e-02\n",
      "    -1.08449295e-01  6.18622079e-03]\n",
      "   [ 2.47696504e-01  4.52178866e-02  1.86342560e-02 ... -9.91150215e-02\n",
      "    -1.95752792e-02  1.35612544e-02]\n",
      "   ...\n",
      "   [-1.78822935e-01 -1.21151604e-01  1.79511294e-01 ... -9.01654735e-02\n",
      "     3.56997326e-02  1.01952873e-01]\n",
      "   [-2.76113600e-01  8.87552351e-02  1.62900686e-01 ...  7.44532347e-02\n",
      "    -8.26286077e-02  1.28966451e-01]\n",
      "   [ 1.14964269e-01 -9.04609710e-02 -1.96785554e-01 ...  9.26992893e-02\n",
      "    -7.46868104e-02 -2.97489725e-02]]\n",
      "\n",
      "  [[-3.15780789e-01 -3.70966755e-02  1.22262403e-01 ...  4.24038172e-02\n",
      "     7.44857341e-02  2.11565774e-02]\n",
      "   [ 1.08525872e-01 -1.04055174e-01 -1.59497574e-01 ... -3.16627622e-02\n",
      "     1.88779482e-03 -1.29715726e-01]\n",
      "   [ 1.64233238e-01  1.40930519e-01  1.60681292e-01 ... -4.31194790e-02\n",
      "    -2.72625089e-01 -5.45258224e-02]\n",
      "   ...\n",
      "   [-1.21517137e-01 -1.98172644e-01  4.02956605e-02 ... -4.96130511e-02\n",
      "    -3.55897658e-02 -7.39784613e-02]\n",
      "   [-6.12415001e-02  1.44968554e-01  4.64088246e-02 ...  1.01801977e-01\n",
      "    -1.15152784e-01  1.25971064e-01]\n",
      "   [ 1.31252021e-01 -1.17622865e-02 -4.64255065e-02 ...  8.56536403e-02\n",
      "     1.23250866e-02 -3.97622958e-02]]\n",
      "\n",
      "  [[ 3.47919129e-02  9.61931571e-02  1.51752710e-01 ... -1.40295029e-02\n",
      "    -1.14107206e-01  5.52989468e-02]\n",
      "   [-7.67533630e-02 -1.26136288e-01 -4.37761992e-02 ...  8.32182616e-02\n",
      "     9.32607278e-02 -1.19828783e-01]\n",
      "   [ 2.17538700e-01 -1.21841237e-01  1.25199273e-01 ...  1.13473885e-01\n",
      "    -2.65563607e-01 -2.84157157e-01]\n",
      "   ...\n",
      "   [-1.25813201e-01 -7.15914443e-02 -2.61635706e-02 ... -2.46783737e-02\n",
      "    -2.53298730e-02 -9.40402448e-02]\n",
      "   [ 5.51836453e-02 -4.87123756e-03  9.45126191e-02 ...  9.21475962e-02\n",
      "    -2.91895986e-01 -1.78161889e-01]\n",
      "   [-5.02644703e-02 -7.20862374e-02  7.87365362e-02 ... -4.72162627e-02\n",
      "    -4.25943261e-04 -1.32769063e-01]]]\n",
      "\n",
      "\n",
      " [[[-4.28869352e-02 -1.28364280e-01 -1.45720735e-01 ... -9.60247293e-02\n",
      "     4.56368141e-02 -6.78184703e-02]\n",
      "   [ 4.94654067e-02  1.16168909e-01 -5.23357913e-02 ... -1.93269551e-03\n",
      "     5.36052920e-02  6.42324463e-02]\n",
      "   [-2.74426460e-01 -1.06227592e-01 -9.87438485e-02 ... -2.60844901e-02\n",
      "    -2.10623756e-01  5.95251285e-02]\n",
      "   ...\n",
      "   [-4.25784290e-02 -6.23039762e-03  3.62233780e-02 ... -5.25395349e-02\n",
      "     6.40987605e-02 -1.23957738e-01]\n",
      "   [-7.21350964e-03 -8.11806172e-02 -1.49508700e-01 ... -1.26961321e-02\n",
      "    -1.06780179e-01  1.98114827e-01]\n",
      "   [-5.30521832e-02  1.66084785e-02  1.38792410e-01 ... -8.87175351e-02\n",
      "     2.28434242e-03 -1.31936550e-01]]\n",
      "\n",
      "  [[-2.86639541e-01 -8.52911770e-02 -1.03945225e-01 ... -1.05779663e-01\n",
      "     7.23858327e-02  1.80741206e-01]\n",
      "   [-1.12630747e-01  8.95073041e-02  8.11709277e-03 ...  9.97341797e-02\n",
      "     6.35735467e-02 -7.29586035e-02]\n",
      "   [-1.31748214e-01 -8.23564604e-02 -2.15769947e-01 ...  2.17329897e-02\n",
      "    -2.22110674e-01 -1.07539326e-01]\n",
      "   ...\n",
      "   [-6.53288141e-02  1.20985381e-01  1.21317632e-01 ...  7.41799623e-02\n",
      "    -1.15494970e-02 -8.81520510e-02]\n",
      "   [-4.66310270e-02 -1.20603442e-02 -7.69041330e-02 ... -6.93288147e-02\n",
      "    -1.80629164e-01 -2.75308471e-02]\n",
      "   [-1.48247689e-01  4.40698341e-02 -2.55693588e-02 ...  3.97772118e-02\n",
      "     7.99940620e-03  8.02225843e-02]]\n",
      "\n",
      "  [[-3.59277055e-02 -1.85621064e-02  5.03918566e-02 ... -1.35630131e-01\n",
      "    -7.61768296e-02  7.43057728e-02]\n",
      "   [-2.57817656e-01  4.24821079e-02 -3.85722667e-02 ...  1.35235665e-02\n",
      "    -1.10105034e-02  7.45179281e-02]\n",
      "   [-9.17909294e-02  6.12626299e-02 -6.35419562e-02 ... -3.24089266e-02\n",
      "    -2.66222179e-01 -5.45497946e-02]\n",
      "   ...\n",
      "   [-3.25026475e-02  8.92194211e-02  1.17215693e-01 ...  1.94598659e-04\n",
      "    -2.36452799e-02  1.62835360e-01]\n",
      "   [ 1.94390211e-02  1.42548839e-02 -7.46761262e-02 ... -9.56893861e-02\n",
      "    -3.31623197e-01 -7.25565329e-02]\n",
      "   [-8.82451534e-02  8.36816654e-02 -1.86431274e-01 ...  1.07776068e-01\n",
      "     4.05612914e-03 -8.67437050e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.84384540e-01 -2.16668040e-01 -2.13551149e-01 ... -1.03222383e-02\n",
      "    -1.73107579e-01  1.41484097e-01]\n",
      "   [ 7.74815604e-02 -2.35723667e-02  2.03263629e-02 ... -7.81018287e-02\n",
      "    -5.68387955e-02 -2.27830168e-02]\n",
      "   [ 9.77671426e-03  1.54225370e-02 -1.82716921e-01 ...  2.26801895e-02\n",
      "     2.24684980e-02 -1.62670389e-01]\n",
      "   ...\n",
      "   [ 1.49281710e-01 -2.21972205e-02 -4.64652898e-03 ... -9.07252133e-02\n",
      "    -5.93882427e-02 -5.49318120e-02]\n",
      "   [ 2.73956060e-01 -1.06035255e-01 -1.14274502e-01 ...  1.02642188e-02\n",
      "    -4.32053693e-02  6.19158261e-02]\n",
      "   [ 9.53100063e-03 -4.68739644e-02  4.92730103e-02 ... -3.76965106e-02\n",
      "     6.19464032e-02  5.55131212e-03]]\n",
      "\n",
      "  [[-2.55061924e-01 -2.22118467e-01 -2.66867965e-01 ... -1.49523783e-02\n",
      "     3.33276279e-02  1.88338980e-01]\n",
      "   [-6.25400320e-02 -1.05297342e-01  6.72199428e-02 ... -1.12483166e-01\n",
      "    -2.96347849e-02  3.21049653e-02]\n",
      "   [ 3.81449461e-02  9.46686491e-02 -1.60363782e-02 ... -4.91348153e-04\n",
      "     2.75292285e-02 -2.58515745e-01]\n",
      "   ...\n",
      "   [-8.68333727e-02 -1.25890717e-01  1.41203225e-01 ... -5.77144399e-02\n",
      "    -6.37670700e-03  2.73450967e-02]\n",
      "   [ 9.69870687e-02  5.32000810e-02 -1.38367757e-01 ...  2.17486508e-02\n",
      "    -2.70941645e-01 -5.04468121e-02]\n",
      "   [ 1.03533015e-01 -5.46377804e-03 -1.40703795e-02 ... -1.00796118e-01\n",
      "     2.31104735e-02  1.17012918e-01]]\n",
      "\n",
      "  [[-2.92876005e-01 -1.73309771e-03 -2.10487187e-01 ... -1.01386286e-01\n",
      "    -7.38502666e-02  3.79877128e-02]\n",
      "   [-5.90905435e-02 -6.00166731e-02 -2.39016954e-02 ... -2.85764169e-02\n",
      "     1.51066318e-01 -5.88401686e-04]\n",
      "   [-2.48492226e-01  8.58756676e-02  8.81099924e-02 ...  1.09737746e-01\n",
      "    -4.84771803e-02  2.10054722e-02]\n",
      "   ...\n",
      "   [-1.50570810e-01 -2.93301016e-01  6.89812750e-02 ... -1.42222807e-01\n",
      "     7.04883598e-03  1.13536321e-01]\n",
      "   [ 8.11778184e-04 -1.46134198e-01 -4.62682918e-02 ... -9.42608342e-02\n",
      "    -2.85850883e-01  1.41129345e-01]\n",
      "   [-2.05822960e-02  3.24914232e-02  2.47748159e-02 ...  1.21884055e-01\n",
      "     9.76126939e-02 -5.25273308e-02]]]]\n",
      "\n",
      "Layer 3 weights:\n",
      "[ 0.00935259 -0.04628199 -0.06459189 -0.1814835  -0.04053292  0.03876161\n",
      " -0.08703821 -0.087543   -0.06921511  0.00239717 -0.00242505 -0.04470111\n",
      " -0.14720379 -0.04348533 -0.06623194 -0.05779888 -0.1063033  -0.06764141\n",
      " -0.17843659 -0.04023978 -0.01022869 -0.02504163  0.0069578   0.03845883\n",
      " -0.01882866 -0.0189379  -0.08330225 -0.07495555 -0.03615089 -0.04551238\n",
      " -0.08967043 -0.06295722 -0.01239248 -0.0617208   0.00971325 -0.01468209\n",
      " -0.06824654 -0.00285767 -0.0456876  -0.10561591 -0.03606944 -0.03168282\n",
      " -0.01996109 -0.04190354  0.00564501 -0.07307252 -0.06725838 -0.00434256\n",
      " -0.01508801 -0.07649095  0.00484771 -0.05821503  0.02148211  0.01449094\n",
      " -0.09373842  0.04294146 -0.00829725 -0.03928949  0.03640514 -0.07435033\n",
      " -0.04719217 -0.00527484 -0.00336588 -0.06298133]\n",
      "\n",
      "Layer 4 weights:\n",
      "[[ 0.0573709   0.03307217  0.03005143 ...  0.04399475  0.01478778\n",
      "   0.07742435]\n",
      " [-0.14464551  0.04685572  0.00736099 ... -0.0120064   0.02549427\n",
      "  -0.24248913]\n",
      " [ 0.04081677  0.05104468 -0.07216827 ...  0.08749185 -0.11443006\n",
      "  -0.02174843]\n",
      " ...\n",
      " [-0.06871622  0.12602615  0.15148495 ... -0.09577826 -0.16560967\n",
      "   0.05382699]\n",
      " [ 0.02045825  0.01610358  0.11606336 ... -0.15101996 -0.05399027\n",
      "  -0.02100562]\n",
      " [ 0.03517762 -0.17968482  0.02493784 ... -0.1554747   0.01798047\n",
      "   0.03557925]]\n",
      "\n",
      "Layer 5 weights:\n",
      "[ 0.03403796  0.10337382 -0.00815891 -0.03894994 -0.0340872  -0.03672517\n",
      " -0.00447454  0.00288667  0.01505949 -0.00914414]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model from the file\n",
    "model = load_model(\"./best_model.h5\")\n",
    "\n",
    "# Get weights of the model\n",
    "weights = model.get_weights()\n",
    "\n",
    "# Print weights\n",
    "# Note: This can result in a very large output if the model is complex\n",
    "for i, weight in enumerate(weights):\n",
    "    print(f\"Layer {i} weights:\\n{weight}\\n\")\n",
    "\n",
    "# If you prefer to save the weights to a file\n",
    "with open('model_weights.txt', 'w') as f:\n",
    "    for i, weight in enumerate(weights):\n",
    "        f.write(f\"Layer {i} weights:\\n{weight}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3144d37-1a5e-4d8f-82e7-05a69c63ff58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and biases were successfully saved to cnnNeuroYONGAweight.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Assuming `model` is your trained Keras model\n",
    "\n",
    "def extract_weights_and_biases(model):\n",
    "    layers_data = []\n",
    "    for layer in model.layers:\n",
    "        # Initialize a dictionary to store layer data\n",
    "        layer_data = {\n",
    "            \"name\": layer.name,\n",
    "            \"type\": type(layer).__name__\n",
    "        }\n",
    "        # Check if the layer has weights\n",
    "        if layer.get_weights():\n",
    "            weights = layer.get_weights()[0]  # Weights\n",
    "            biases = layer.get_weights()[1]  # Biases\n",
    "            # Convert numpy arrays to list for JSON serialization\n",
    "            layer_data[\"weights\"] = weights.tolist()\n",
    "            layer_data[\"biases\"] = biases.tolist()\n",
    "        \n",
    "        layers_data.append(layer_data)\n",
    "    \n",
    "    return layers_data\n",
    "\n",
    "# Extract weights and biases\n",
    "weights_and_biases = extract_weights_and_biases(model)\n",
    "\n",
    "# Define the file path (modify this path as necessary)\n",
    "file_path = 'cnnNeuroYONGAweight.json'\n",
    "\n",
    "# Write the extracted weights and biases to a JSON file\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(weights_and_biases, f)\n",
    "\n",
    "print(f\"Weights and biases were successfully saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bfd110-25e8-4a68-bb93-072add09e631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
